{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrive traffic data for chicago city using City Of Chicago.\n",
    "\n",
    "This notebook retrieves data on chicago traffic , which is provided by the City of chicago. The data is stored into Kafka, and then used to demonstrate writing the data into Cosmos.\n",
    "\n",
    "The data set used by this notebook is from Chicago Traffic Tracker - Congestion by segments(https://data.cityofchicago.org/resource/8v9j-bter.json.\n",
    "\n",
    "## Requirements\n",
    "\n",
    "* An Azure Virtual Network\n",
    "* A Spark (2.2.0) on HDInsight 3.6 cluster, inside the virtual network\n",
    "* A Kafka on HDInsight 3.6 cluster, inside the virtual network\n",
    "\n",
    "## Load packages\n",
    "Run the next cell to load packages used by this notebook:\n",
    "\n",
    "* spark-streaming-kafka-0-8_2.10, version 2.2.0 - Used to write data to Kafka.\n",
    "* gson version 2.4 - Used for JSON parsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>7</td><td>application_1543170503042_0008</td><td>spark</td><td>idle</td><td><a target=\"_blank\" href=\"http://hn1-spark.yr21tghw1lbedojd2c1yzdkfqb.dx.internal.cloudapp.net:8088/proxy/application_1543170503042_0008/\">Link</a></td><td><a target=\"_blank\" href=\"http://wn3-spark.yr21tghw1lbedojd2c1yzdkfqb.dx.internal.cloudapp.net:30060/node/containerlogs/container_e02_1543170503042_0008_01_000001/livy\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{u'kind': 'spark', u'conf': {u'spark.jars.packages': u'org.apache.spark:spark-streaming-kafka-0-8_2.10:2.2.0,com.google.code.gson:gson:2.4', u'spark.jars.excludes': u'org.scala-lang:scala-reflect,org.apache.spark:spark-tags_2.11'}}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>7</td><td>application_1543170503042_0008</td><td>spark</td><td>idle</td><td><a target=\"_blank\" href=\"http://hn1-spark.yr21tghw1lbedojd2c1yzdkfqb.dx.internal.cloudapp.net:8088/proxy/application_1543170503042_0008/\">Link</a></td><td><a target=\"_blank\" href=\"http://wn3-spark.yr21tghw1lbedojd2c1yzdkfqb.dx.internal.cloudapp.net:30060/node/containerlogs/container_e02_1543170503042_0008_01_000001/livy\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure -f\n",
    "{\n",
    "    \"conf\": {\n",
    "        \"spark.jars.packages\": \"org.apache.spark:spark-streaming-kafka-0-8_2.10:2.2.0,com.google.code.gson:gson:2.4\",\n",
    "        \"spark.jars.excludes\": \"org.scala-lang:scala-reflect,org.apache.spark:spark-tags_2.11\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Kafka topic\n",
    "Provide the Zookeeper host information for Kafka cluster. \n",
    "The following steps to get this information:\n",
    "* From __Azure PowerShell__:\n",
    "\n",
    "    ```powershell\n",
    "$creds = Get-Credential -UserName \"admin\" -Message \"Enter the HDInsight login\"\n",
    "$clusterName = Read-Host -Prompt \"Enter the Kafka cluster name\"\n",
    "$resp = Invoke-WebRequest -Uri \"https://$clusterName.azurehdinsight.net/api/v1/clusters/$clusterName/services/ZOOKEEPER/components/ZOOKEEPER_SERVER\" `\n",
    "    -Credential $creds `\n",
    "    -UseBasicParsing\n",
    "$respObj = ConvertFrom-Json $resp.Content\n",
    "$zkHosts = $respObj.host_components.HostRoles.host_name[0..1]\n",
    "($zkHosts -join \":2181,\") + \":2181\"\n",
    "    ````\n",
    "\n",
    "The return value is:\n",
    "\n",
    "'zk0-kafka.yr21tghw1lbedojd2c1yzdkfqb.dx.internal.cloudapp.net:2181,zk1-kafka.yr21tghw1lbedojd2c1yzdkfqb.dx.internal.cloudapp.net:2181'\n",
    "\n",
    "Replace the `YOUR_ZOOKEEPER_HOSTS` in the next cell with the returned value, and then run the cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "/usr/hdp/current/kafka-broker/bin/kafka-topics.sh --create --replication-factor 3 --partitions 8 --topic trafficdata --zookeeper 'zk0-kafka.yr21tghw1lbedojd2c1yzdkfqb.dx.internal.cloudapp.net:2181,zk1-kafka.yr21tghw1lbedojd2c1yzdkfqb.dx.internal.cloudapp.net:2181'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve data from city of chicago.\n",
    "\n",
    "Run the next cell to load data on traffic congestion from city of chicago website. The function calls the REST API every 15 minutes;  the interval at which the site refreshes the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 1000 rows of Traffic data."
     ]
    }
   ],
   "source": [
    "// Load the data from the City of chicago API for traffic congestion data\n",
    "def loaddata(){\n",
    "val url=\"https://data.cityofchicago.org/resource/8v9j-bter.json\"\n",
    "val result = scala.io.Source.fromURL(url).mkString\n",
    "\n",
    "// Since the REST API returns an array of items,\n",
    "// it's easier to use as an array than deal with streaming\n",
    "import com.google.gson.Gson\n",
    "val gson = new Gson()\n",
    "val jsonDataArray = gson.fromJson(result, classOf[Array[Object]])\n",
    "\n",
    "println(\"Retrieved \" + jsonDataArray.length + \" rows of Traffic data.\")\n",
    "\n",
    "thread.sleep(900000,loaddata)\n",
    "}\n",
    "loaddata()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the Kafka broker hosts information\n",
    "\n",
    "Create kafka broker hosts for the Kafka cluster. This is used to write data to the Kafka cluster. To get the broker host information,\n",
    "\n",
    "* From Azure Powershell:\n",
    "\n",
    "    ```powershell\n",
    "$creds = Get-Credential -UserName \"admin\" -Message \"Enter the HDInsight login\"\n",
    "$clusterName = Read-Host -Prompt \"Enter the Kafka cluster name\"\n",
    "$resp = Invoke-WebRequest -Uri \"https://$clusterName.azurehdinsight.net/api/v1/clusters/$clusterName/services/KAFKA/components/KAFKA_BROKER\" `\n",
    "  -Credential $creds `\n",
    "  -UseBasicParsing\n",
    "$respObj = ConvertFrom-Json $resp.Content\n",
    "$brokerHosts = $respObj.host_components.HostRoles.host_name[0..1]\n",
    "($brokerHosts -join \":9092,\") + \":9092\"\n",
    "    ```\n",
    "    \n",
    " Output from execution of previous code is,\n",
    "\"wn0-kafka.yr21tghw1lbedojd2c1yzdkfqb.dx.internal.cloudapp.net:9092,wn1-kafka.yr21tghw1lbedojd2c1yzdkfqb.dx.internal.cloudapp.net:9092\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kafkaTopic: String = trafficdata"
     ]
    }
   ],
   "source": [
    "// The Kafka broker hosts and topic used to write to Kafka\n",
    "val kafkaBrokers=\"wn0-kafka.yr21tghw1lbedojd2c1yzdkfqb.dx.internal.cloudapp.net:9092,wn1-kafka.yr21tghw1lbedojd2c1yzdkfqb.dx.internal.cloudapp.net:9092\"\n",
    "val kafkaTopic=\"trafficdata\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send the data to Kafka\n",
    "\n",
    "Begin streaming data to Kafka. There is a delay of 1 second (1000ms) after each send, so cell stays active several minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished writting to Kafka"
     ]
    }
   ],
   "source": [
    "// Import classes used to write to Kafka via a producer\n",
    "import org.apache.kafka.clients.producer.{KafkaProducer, ProducerConfig, ProducerRecord}\n",
    "import java.util.HashMap\n",
    "\n",
    "// Create the Kafka producer\n",
    "val producerProperties = new HashMap[String, Object]()\n",
    "producerProperties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, kafkaBrokers)\n",
    "producerProperties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,\n",
    "                           \"org.apache.kafka.common.serialization.StringSerializer\")\n",
    "producerProperties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG,\n",
    "                           \"org.apache.kafka.common.serialization.StringSerializer\")\n",
    "val producer = new KafkaProducer[String, String](producerProperties)\n",
    "\n",
    "// Iterate over data and emit to Kafka\n",
    "jsonDataArray.foreach { row =>\n",
    "                // Get the row as a JSON string\n",
    "                val jsonData = gson.toJson(row)\n",
    "                // Create the message for Kafka\n",
    "                val message = new ProducerRecord[String, String](kafkaTopic, null, jsonData)\n",
    "                // Send the message\n",
    "                producer.send(message)\n",
    "                // Sleep a bit between sends to simulate streaming data\n",
    "                Thread.sleep(1000)\n",
    "             }\n",
    "producer.close()\n",
    "println(\"Finished writting to Kafka\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data to cosmos-db and stream it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
